# TensorBoard メトリクス解説ガイド

## 📊 深層強化学習におけるTensorBoardメトリクスの見方

このドキュメントでは、Bittle四足歩行ロボットの深層強化学習において、TensorBoardで表示される各メトリクスの意味と適切な見方について説明します。

---

## 🎯 **評価メトリクス (Eval Metrics)**

### 1. `eval/mean_ep_length` - 平均エピソード長
**意味**: 評価時に1エピソードが平均何ステップ続いたか

**見方**:
- **高い値 (50-500)**: ロボットが長く生存している → 良い学習
- **低い値 (1-10)**: すぐに転倒している → 学習不足
- **目標値**: 200-500ステップ（設定されたmax_episode_stepsに近い）

**判断基準**:
- ✅ **良好**: 100以上で安定
- ⚠️ **注意**: 50以下で不安定
- ❌ **問題**: 10以下で頻繁転倒

### 2. `eval/mean_reward` - 平均報酬
**意味**: 評価時の1エピソード平均報酬

**見方**:
- **正の値**: ロボットが前進・生存している
- **負の値**: 転倒ペナルティが大きい
- **上昇傾向**: 学習が進んでいる

**判断基準**:
- ✅ **良好**: 0.5以上で上昇傾向
- ⚠️ **注意**: 0.1-0.5で停滞
- ❌ **問題**: 負の値で転倒頻発

---

## ⚡ **パフォーマンスメトリクス**

### 3. `time/fps` - フレームレート
**意味**: 1秒間に処理できるステップ数

**見方**:
- **高い値 (100+)**: 高速学習
- **低い値 (<50)**: 計算リソース不足
- **安定性**: 変動が少ない方が良い

**判断基準**:
- ✅ **良好**: 100以上で安定
- ⚠️ **注意**: 50-100でやや遅い
- ❌ **問題**: 50以下で非常に遅い

---

## 🧠 **学習メトリクス (Train Metrics)**

### 4. `train/approx_kl` - 近似KLダイバージェンス
**意味**: ポリシーの更新前後の分布の違い

**見方**:
- **0.01-0.03**: 適切な更新幅
- **0.05以上**: 更新が大きすぎる（不安定）
- **0.001以下**: 更新が小さすぎる（学習が遅い）

**判断基準**:
- ✅ **良好**: 0.01-0.03で安定
- ⚠️ **注意**: 0.05以上で不安定
- ❌ **問題**: 0.1以上で学習破綻

### 5. `train/clip_fraction` - クリップ割合
**意味**: PPOでクリップされたアクションの割合

**見方**:
- **0.1-0.3**: 適切なクリップ範囲
- **0.5以上**: クリップが多すぎる（学習が不安定）
- **0.05以下**: クリップが少なすぎる（学習が遅い）

**判断基準**:
- ✅ **良好**: 0.1-0.3で安定
- ⚠️ **注意**: 0.4以上で不安定
- ❌ **問題**: 0.8以上で学習破綻

### 6. `train/clip_range` - クリップ範囲
**意味**: PPOのクリップ範囲パラメータ

**見方**:
- **0.2**: デフォルト値（適切）
- **0.1-0.3**: 通常の範囲
- **0.5以上**: 大きすぎる（不安定）

**判断基準**:
- ✅ **良好**: 0.2で安定
- ⚠️ **注意**: 0.3以上で不安定
- ❌ **問題**: 0.5以上で学習破綻

### 7. `train/entropy_loss` - エントロピー損失
**意味**: ポリシーの探索性（ランダム性）

**見方**:
- **-10から-20**: 適切な探索性
- **-5以上**: 探索が多すぎる（不安定）
- **-30以下**: 探索が少なすぎる（学習が遅い）

**判断基準**:
- ✅ **良好**: -10から-20で安定
- ⚠️ **注意**: -5以上で不安定
- ❌ **問題**: -30以下で学習停滞

### 8. `train/explained_variance` - 説明された分散
**意味**: 価値関数の予測精度

**見方**:
- **0.5-0.9**: 良好な予測精度
- **0.3以下**: 予測精度が低い
- **1.0**: 完璧な予測（過学習の可能性）

**判断基準**:
- ✅ **良好**: 0.5-0.9で上昇傾向
- ⚠️ **注意**: 0.3-0.5で停滞
- ❌ **問題**: 0.1以下で予測失敗

### 9. `train/learning_rate` - 学習率
**意味**: 現在の学習率

**見方**:
- **0.0003**: デフォルト値（適切）
- **0.0001-0.001**: 通常の範囲
- **0.01以上**: 大きすぎる（不安定）

**判断基準**:
- ✅ **良好**: 0.0003で安定
- ⚠️ **注意**: 0.001以上で不安定
- ❌ **問題**: 0.01以上で学習破綻

### 10. `train/loss` - 全体損失
**意味**: ポリシーと価値関数の合計損失

**見方**:
- **負の値**: 正常（報酬最大化）
- **正の値**: 異常（ペナルティが大きい）
- **安定性**: 変動が少ない方が良い

**判断基準**:
- ✅ **良好**: 負の値で安定
- ⚠️ **注意**: 正の値で不安定
- ❌ **問題**: 大きな正の値で学習破綻

### 11. `train/policy_gradient_loss` - ポリシー勾配損失
**意味**: ポリシー関数の損失

**見方**:
- **負の値**: 正常（報酬最大化）
- **正の値**: 異常（ペナルティが大きい）
- **安定性**: 変動が少ない方が良い

**判断基準**:
- ✅ **良好**: 負の値で安定
- ⚠️ **注意**: 正の値で不安定
- ❌ **問題**: 大きな正の値で学習破綻

### 12. `train/std` - 標準偏差
**意味**: アクションの分散（探索性）

**見方**:
- **0.5-1.5**: 適切な探索性
- **0.1以下**: 探索が少なすぎる
- **2.0以上**: 探索が多すぎる（不安定）

**判断基準**:
- ✅ **良好**: 0.5-1.5で安定
- ⚠️ **注意**: 0.1以下で探索不足
- ❌ **問題**: 2.0以上で不安定

### 13. `train/value_loss` - 価値関数損失
**意味**: 価値関数の予測誤差

**見方**:
- **0.1-0.5**: 適切な予測誤差
- **0.05以下**: 予測が良すぎる（過学習の可能性）
- **1.0以上**: 予測が悪すぎる（学習不足）

**判断基準**:
- ✅ **良好**: 0.1-0.5で安定
- ⚠️ **注意**: 0.05以下で過学習
- ❌ **問題**: 1.0以上で学習不足

---

## 📈 **学習進行の判断方法**

### 🎯 **良好な学習の特徴**
1. **`eval/mean_reward`**: 0.5以上で上昇傾向
2. **`eval/mean_ep_length`**: 100以上で安定
3. **`train/approx_kl`**: 0.01-0.03で安定
4. **`train/explained_variance`**: 0.5以上で上昇傾向
5. **`train/loss`**: 負の値で安定

### ⚠️ **注意すべき状況**
1. **`eval/mean_reward`**: 0.1以下で停滞
2. **`train/approx_kl`**: 0.05以上で不安定
3. **`train/clip_fraction`**: 0.5以上で不安定
4. **`train/explained_variance`**: 0.3以下で予測失敗

### ❌ **問題のある状況**
1. **`eval/mean_reward`**: 負の値で転倒頻発
2. **`train/approx_kl`**: 0.1以上で学習破綻
3. **`train/clip_fraction`**: 0.8以上で学習破綻
4. **`train/loss`**: 大きな正の値で学習破綻

---

## 🔧 **問題解決の指針**

### 学習が遅い場合
- **学習率を上げる**: `learning_rate` を 0.0003 → 0.001
- **バッチサイズを増やす**: `batch_size` を 64 → 128
- **エポック数を増やす**: `n_epochs` を 10 → 20

### 学習が不安定な場合
- **学習率を下げる**: `learning_rate` を 0.0003 → 0.0001
- **クリップ範囲を狭める**: `clip_range` を 0.2 → 0.1
- **バッチサイズを減らす**: `batch_size` を 64 → 32

### 探索が不足している場合
- **エントロピー係数を上げる**: `ent_coef` を 0.01 → 0.1
- **初期標準偏差を上げる**: ポリシー初期化を調整

---

## 📊 **監視の優先順位**

### 🥇 **最重要メトリクス**
1. `eval/mean_reward` - 学習成果の直接指標
2. `eval/mean_ep_length` - ロボットの生存能力
3. `train/approx_kl` - 学習の安定性

### 🥈 **重要メトリクス**
4. `train/explained_variance` - 価値関数の精度
5. `train/loss` - 全体の学習状況
6. `train/clip_fraction` - PPOの安定性

### 🥉 **参考メトリクス**
7. `train/entropy_loss` - 探索性
8. `train/value_loss` - 価値関数の学習状況
9. `time/fps` - 計算効率

---

## 💡 **実用的な監視方法**

### 1. **リアルタイム監視**
```bash
# 学習ログの監視
docker logs -f bittle-final-training

# TensorBoardの起動
tensorboard --logdir logs/tensorboard --host 0.0.0.0 --port 6007
```

### 2. **定期的なチェック**
- **10分ごと**: `eval/mean_reward` の変化
- **30分ごと**: 全メトリクスの傾向
- **1時間ごと**: 学習パラメータの調整検討

### 3. **問題発見時の対応**
- **学習停止**: 不安定なメトリクスが続く場合
- **パラメータ調整**: 学習効率が悪い場合
- **モデル保存**: 良好な性能が確認できた場合

---

このガイドを参考に、TensorBoardのメトリクスを適切に解釈し、効果的な学習監視を行ってください。
